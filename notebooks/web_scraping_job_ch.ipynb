{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import re\n",
    "import collections\n",
    "\n",
    "sys.path.insert(0, os.path.dirname(os.path.abspath('../src')))\n",
    "from src.getjobsch import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Jobs.ch\n",
    "\n",
    "As a job seeker, one has to search through job portals to find most relevant jobs related to your profile. In this exercise, your goal is to find all jobs related to keywords: “Data Scientist”, “Data Analyst”, “Python Developer”, “Data Engineer”, “Data Manager”, “Data Architect”, “Big Data Analyst” and “Data Python” on jobs.ch.\n",
    "1. Download all necessary information (including job title, date, company name, location…) for all webpages.\n",
    "2. Using the information obtained, perform a descriptive analysis on this data including questions:\n",
    "   - How many jobs are shared between these categories?\n",
    "   - How much the keywords: “Data Analyst” and “Big Data Analyst” overlap?\n",
    "   - Are there some companies doing more hires than average?\n",
    "   - How many jobs are there in different Kantons?\n",
    "   - Is “machine learning” keyword more often in data scientist or data analyst jobs?\n",
    "   - What is the distribution of most common keywords between and across categories?\n",
    "3. Produce a report in the form of a clean notebook (or jupyter slides), with commented code and markdown cells for structuring and interpretations."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Scraping\n",
    "\n",
    "The file `src/getjobsch` contains the necesary functions to pull infomation from https://www.jobs.ch/en/vacancies/. The function works in the following way:\n",
    "- Receives a list of job positions on natural language\n",
    "- The function `clean_job_keywords` will transform those key words to search keywords by removing white spaces and replacing them with `%20` characters\n",
    "- Once the necesary keywords were obtained the function `df_full_data` will proceed to pull info for each job in the following way:\n",
    "  - Get the number of available pages for each job position\n",
    "  - For each of the available pages, scrap an individual text box using the function `get_data_one_job` and concatenating the info by using the function `df_all_jobs`\n",
    "  - In case no job postings are found an error should be printed (see example below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key words to be searched\n",
    "job_positions = [\"Data Engineer\", \"Data Scientist\", \"Data Analyst\", \"Python Developer\", \"Data Manager\", \"Data Architect\", \"Big Data Analyst\", \"Data Python\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Run the function to get both errors and \n",
    "# df_all = df_full_data(job_positions)\n",
    "\n",
    "# # In this case we should not have errors\n",
    "# errors = df_all[\"errors\"]\n",
    "# errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print the found jobs\n",
    "# df_jobs = df_all[\"results\"]\n",
    "# df_jobs.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load found jobs\n",
    "df_jobs = pd.read_csv(\"../data/raw/df_jobs_ch.csv\", index_col=[0])\n",
    "df_jobs.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is an index problem for some cases and therefore some job types do not make sense\n",
    "df_jobs.job_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "programming_summary, skills_summary, python_summary, errors = get_job_keywords(df_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 39 positions without available information\n"
     ]
    }
   ],
   "source": [
    "print(f\"There were {len(errors['errors'])} positions without available information\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_jobs.to_csv(\"../data/raw/df_jobs_ch.csv\")\n",
    "# pd.DataFrame(dict(programming_summary).items()).to_csv(\"../data/raw/programming_summary.csv\")\n",
    "# pd.DataFrame(dict(python_summary).items()).to_csv(\"../data/raw/python_summary.csv\")\n",
    "# pd.DataFrame(dict(skills_summary).items()).to_csv(\"../data/raw/skills_summary.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping -- Continued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_urls = df_jobs[\"job_link\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "programming_count = []\n",
    "skills_count = []\n",
    "python_count = []\n",
    "errors = []\n",
    "\n",
    "for i, ju in enumerate(job_urls):\n",
    "    flag_1 = False\n",
    "    flag_2 = False\n",
    "    sec_page = requests.get(ju)\n",
    "    sec_soup = BeautifulSoup(sec_page.content, \"html.parser\")\n",
    "    \n",
    "    try:\n",
    "        job_desc = sec_soup.find(\"div\", {\"data-cy\" : \"vacancy-description\"})\n",
    "        job_desc_text = job_desc.text\n",
    "    except AttributeError:\n",
    "        job_desc_text = \"\"\n",
    "        flag_1 = True\n",
    "    \n",
    "    if job_desc == None:\n",
    "        try:\n",
    "            job_desc = sec_soup.find(\"iframe\", {\"data-cy\" : \"detail-vacancy-iframe-content\"}).find_next()\n",
    "            job_desc_text = job_desc.text\n",
    "        except AttributeError:\n",
    "            job_desc_text = \"\"\n",
    "            flag_2 = True\n",
    "    \n",
    "    if flag_1 and flag_2:\n",
    "        errors.append(ju)\n",
    "\n",
    "    job_desc_text = job_desc_text.translate(job_desc_text.maketrans(\"\", \"\", '!\"$%&\\'()*,-./:;<=>?@[\\\\]^_`{|}~'))\n",
    "    job_desc_text = job_desc_text.lower()\n",
    "    job_desc_words = job_desc_text.split()\n",
    "    \n",
    "    for word in job_desc_words:\n",
    "        if word in keywords_programming.keys():\n",
    "            programming_count.append(word) #  = word_count.get(word, 0) + 1\n",
    "        if word in keywords_skills.keys():\n",
    "            skills_count.append(word)\n",
    "        if word in keywords_python.keys():\n",
    "            python_count.append(word)\n",
    "    \n",
    "    programming_summary = collections.Counter(programming_count)\n",
    "    skills_summary = collections.Counter(skills_count)\n",
    "    python_summary = collections.Counter(python_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'python': 978, 'sql': 764, 'r': 331, 'javascript': 129, 'plsql': 108, 'powershell': 101, 'scala': 87, 'c++': 87, 'pascal': 87, 'php': 75, 'matlab': 68, 'perl': 54, 'vba': 54, 'java': 28, 'go': 28, 'c#': 14, 'bash': 14, 'typescript': 14, 'html': 7})\n"
     ]
    }
   ],
   "source": [
    "print(programming_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'pytorch': 141, 'pandas': 54, 'scikitlearn': 54, 'tensorflow': 54, 'plotly': 14})\n"
     ]
    }
   ],
   "source": [
    "print(python_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'aws': 453, 'sap': 308, 'excel': 279, 'powerbi': 249, 'hadoop': 230, 'tableau': 169, 'linux': 122, 'sharepoint': 61, 'pandas': 54, 'spss': 54, 'jquery': 7, 'spark': 4})\n"
     ]
    }
   ],
   "source": [
    "print(skills_summary)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Scrapping -- Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_url = df_jobs[[\"job_link\"]].values[1][0] # 'https://www.jobs.ch/en/vacancies/detail/3fa23bd2-215b-4500-83cf-317d15b71d13/?source=vacancy_search'\n",
    "sec_page = requests.get(sec_url)\n",
    "sec_soup = BeautifulSoup(sec_page.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sec_soup.find(\"div\", {\"data-cy\" : \"vacancy-description\"}).text.find(\"Git\") > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Git'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sec_soup.find(\"div\", {\"data-cy\" : \"vacancy-description\"}).text[936:939]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ul class=\"Ul-sc-1n42qu0-0 Ul-sc-1otw97l-0 JJPIu kNGQob\"><li class=\"Li-sc-ennkmk-0 Li-sc-l8g2j9-0\"><span>Supports the Market Data team with building new external data feeds for business or system needs in good quality</span><br/></li><br/><li class=\"Li-sc-ennkmk-0 Li-sc-l8g2j9-0\"><span>Establish new data connections within our new cloud solution end-to-end.</span><br/></li><br/><li class=\"Li-sc-ennkmk-0 Li-sc-l8g2j9-0\"><span>Help the Business community and the Market Data team in migrating existing data and business objects to new platforms</span></li></ul>\n",
      "<ul class=\"Ul-sc-1n42qu0-0 Ul-sc-1otw97l-0 JJPIu kNGQob\"><br/><li class=\"Li-sc-ennkmk-0 Li-sc-l8g2j9-0\"><span>You successfully completed a Bachelor's degree in IT sci-ence, Data Engineering, or similar</span><br/></li><br/><li class=\"Li-sc-ennkmk-0 Li-sc-l8g2j9-0\"><span>You have experience working as a Data Engineer, Data Scientist, Data Analyst, or similar</span><br/></li><br/><li class=\"Li-sc-ennkmk-0 Li-sc-l8g2j9-0\"><span>You are a team player with good interpersonal skills and a problem-solving attitude</span><br/></li><br/><li class=\"Li-sc-ennkmk-0 Li-sc-l8g2j9-0\"><span>You are proficient in Python or/and other programming languages</span><br/></li><br/><li class=\"Li-sc-ennkmk-0 Li-sc-l8g2j9-0\"><span>You have experience working as a team member in DevOps and Git version control</span><br/></li><br/><li class=\"Li-sc-ennkmk-0 Li-sc-l8g2j9-0\"><span>You have had exposure to projects in Cloud and Cloud services</span><br/></li><br/><li class=\"Li-sc-ennkmk-0 Li-sc-l8g2j9-0\"><span>Know how in PowerBI would be a plus</span><br/></li><br/><li class=\"Li-sc-ennkmk-0 Li-sc-l8g2j9-0\"><span>Having Market Data knowledge in Commodity Markets would be a huge plus</span><br/></li><br/><li class=\"Li-sc-ennkmk-0 Li-sc-l8g2j9-0\"><span>You are fluent in English, German is considered an advantage</span><br/></li><br/></ul>\n"
     ]
    }
   ],
   "source": [
    "ll = sec_soup.find(\"div\", {\"data-cy\" : \"vacancy-description\"}).find_all(\"ul\", {\"class\" : \"Ul-sc-1n42qu0-0 Ul-sc-1otw97l-0 JJPIu kNGQob\"}) # .find_all(\"span\")\n",
    "for l in ll:\n",
    "    l.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1894"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sec_soup.find(\"iframe\", {\"data-cy\" : \"detail-vacancy-iframe-content\"}).find_next().text.find(\"Python\") # find_all(\"p\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dskit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
